{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 영상을 받아 rppg(r,g,b) raw data, timestamp 검출\n",
    "# A 코드는 산소포화도만 구할때 사용하는 코드\n",
    "# B 코드는 ppg r,g,b에서 처리를 통해 chrom 방식으로 노이즈 제거한 후 ppg raw 신호 추출하는 코드\n",
    "# B 코드의 결과는 r,g,b 따로가 아니라 이걸 합쳐서 하나의 PPG 신호가 나옴\n",
    "\n",
    "# B 코드는 그냥 참고용이고 현재 방법의 산소포화도 구할때는 필요 없어요!"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A 코드 : 산소포화도만 구할때 사용한 코드"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from scipy import signal\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from utils import kcf\n",
    "from utils import skinsegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(file_path, file_num):\n",
    "    is_tracking = False\n",
    "    track_toler = 1\n",
    "    prev_bbox = [0, 0, 0, 0]\n",
    "    detect_th = 0.5\n",
    "    detector = cv2.dnn.readNetFromTensorflow('model/face_detector.pb', 'model/face_detector.pbtxt') #얼굴 검출\n",
    "    tracker = kcf.KCFTracker() #얼굴 tracking\n",
    "\n",
    "    r_buffer = []\n",
    "    g_buffer = []\n",
    "    b_buffer = []\n",
    "\n",
    "   # cap = cv2.VideoCapture(0, cv2.CAP_DSHOW) #카메라로 촬영하면서 바로 ppg 신호 추출할때 사용\n",
    "   # h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "   # w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    file_list = os.listdir(file_path)   # 지정한 디렉토리 내 모든 파일과 디렉토리의 list return\n",
    "    file_list = sorted(file_list, key= lambda x: int(os.path.splitext(x)[0].split('_')[1]))\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        # _, frame = cap.read() #카메라로 촬영하면서 바로 ppg 신호 추출할때 사용\n",
    "        frame = cv2.imread('%s/%s'%(file_path, file_list[count]), cv2.IMREAD_COLOR)\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        curr_bbox = []\n",
    "        # 검출된 얼굴이 존재하지 않는 경우 검출 수행\n",
    "        if not is_tracking:\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), [104., 117., 123.], False, True)\n",
    "            detector.setInput(blob)\n",
    "            detections = detector.forward()\n",
    "            bboxes = [detections[0, 0, i, 3:7] for i in range(detections.shape[2]) if detections[0, 0, i, 2] >= detect_th]\n",
    "            if len(bboxes) > 0:\n",
    "                # 가장 큰 얼굴 하나만 검출\n",
    "                bboxes = sorted(bboxes, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]), reverse=True)\n",
    "                bboxes = [(rect * np.array([w, h, w, h])).astype('int') for rect in bboxes]\n",
    "                curr_bbox = [bboxes[0][0], bboxes[0][1], bboxes[0][2]-bboxes[0][0], bboxes[0][3]-bboxes[0][1]]  # (xs,ys,xe,ye) -> (x,y,w,h)\n",
    "                \n",
    "                # 트래커에 현재 얼굴 위치 등록\n",
    "                tracker.init(frame, curr_bbox)\n",
    "                is_tracking = True\n",
    "        \n",
    "        # 검출된 얼굴이 존재하는 경우 위치 업데이트\n",
    "        elif is_tracking:\n",
    "            is_tracking, curr_bbox = tracker.update(frame)\n",
    "            curr_bbox = [curr if abs(curr-prev) > track_toler else prev for curr, prev in zip(curr_bbox, prev_bbox)]\n",
    "            prev_bbox = curr_bbox\n",
    "        \n",
    "        try:\n",
    "#             cv2.rectangle(frame, (curr_bbox[1], curr_bbox[0]), (curr_bbox[3], curr_bbox[0]), (0,0,255), 1)\n",
    "            \n",
    "            face = frame[curr_bbox[1]:curr_bbox[1]+curr_bbox[3], curr_bbox[0]:curr_bbox[0]+curr_bbox[0]]\n",
    "            mask = skinsegment.create_skin_mask(face) # 얼굴에서 피부색 영역만 추출\n",
    "            n_pixel = max(1, np.sum(mask))\n",
    "            \n",
    "            ''' rgb '''\n",
    "            b, g, r = cv2.split(face)\n",
    "            r[mask == 0] = 0\n",
    "            g[mask == 0] = 0\n",
    "            b[mask == 0] = 0\n",
    "\n",
    "            r = r.astype(np.float32)\n",
    "            g = g.astype(np.float32)\n",
    "            b = b.astype(np.float32)\n",
    "\n",
    "            r_mean = np.sum(r) / n_pixel\n",
    "            g_mean = np.sum(g) / n_pixel\n",
    "            b_mean = np.sum(b) / n_pixel\n",
    "\n",
    "            r_buffer.append(r_mean)\n",
    "            g_buffer.append(g_mean)\n",
    "            b_buffer.append(b_mean)\n",
    "\n",
    "            cv2.rectangle(frame, (curr_bbox[0], curr_bbox[1]), (curr_bbox[0]+curr_bbox[2], curr_bbox[1]+curr_bbox[3]), (0,0,255), 2)\n",
    "        \n",
    "        except:\n",
    "            r_buffer.append(0.0)\n",
    "            g_buffer.append(0.0)\n",
    "            b_buffer.append(0.0) \n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        count += 1\n",
    "        # 파일을 다 불러왔으면 멈춤\n",
    "        if len(file_list) == count :\n",
    "            break           \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    file_time =[]\n",
    "    for file in file_list:\n",
    "        file_time.append(file.split('_')[-1].split('.')[0])\n",
    "        \n",
    "    return [r_buffer, g_buffer, b_buffer, file_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-0300a0bd8614>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mfile_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'images_2/%d'\u001B[0m\u001B[1;33m%\u001B[0m\u001B[0mfile_num\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mrgb_signal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile_num\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;31m# CHROM 검출\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10, 11): #(*) file_num에 맞게 불러오면 됨 #file_num은 video.ipynb 파일에서 이미지 저장할때 폴더명(=path_num)\n",
    "    # RGB 신호 생성\n",
    "    file_num = i\n",
    "    file_path = 'images_2/%d'%file_num\n",
    "\n",
    "    rgb_signal = run(file_path, file_num)\n",
    "\n",
    "    #ppg rgb 신호와 그 time 엑셀에 저장\n",
    "    with open('data/rppg_2/rppg%d.csv'%file_num, 'w', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow(rgb_signal)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. 처리된 PPG raw signal 구하는 코드(CHORM 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fs = 30\n",
    "minBPM = 42 #최소 심박수 (*)\n",
    "maxBPM = 240 #최대 심박수 (*)\n",
    "\n",
    "# 신호의 추세를 없애는 함수\n",
    "def detrending(data, wsize):\n",
    "    try:\n",
    "        if data.ndim == 1:\n",
    "            data = np.expand_dims(data, axis=0)\n",
    "        n_channel = data.shape[0]\n",
    "        norm = signal.convolve2d(np.ones_like(data), np.ones((n_channel, wsize)), mode='same')\n",
    "        mean = signal.convolve2d(data, np.ones((n_channel, wsize)), mode='same') / norm\n",
    "        return (data - mean) / (mean + 1e-15)\n",
    "    except ValueError:\n",
    "        return data\n",
    "\n",
    "#bandpass-filtering\n",
    "def temporal_bandpass_filter(data, fs, minBPM, maxBPM):\n",
    "    try:\n",
    "        nyq = 60 * fs / 2\n",
    "        coef_vector = signal.butter(5, [minBPM / nyq, maxBPM / nyq], 'bandpass')\n",
    "        return signal.filtfilt(*coef_vector, data)\n",
    "    except ValueError:\n",
    "        return data\n",
    "\n",
    "#평균 심박수 구하는 함수\n",
    "def estimate_average_pulserate(data, fs, minBPM, maxBPM):\n",
    "    f, pxx = signal.periodogram(data, fs=fs, window='hann')\n",
    "    max_peak_idx = np.argmax(pxx)\n",
    "    bpm = int(f[max_peak_idx] * 60)\n",
    "    return min(max(bpm, minBPM), maxBPM)\n",
    "\n",
    "#snr 구하는 함수\n",
    "def calculate_snr(data, fs, fundamental_freq, use_harmonic=False):\n",
    "    f, pxx = signal.periodogram(data, fs=fs, window='hann')\n",
    "\n",
    "    fundamental_range = (fundamental_freq - 2, fundamental_freq + 2)\n",
    "    energy_of_interest = np.sum(pxx[fundamental_range[0]:fundamental_range[1]])\n",
    "\n",
    "    if use_harmonic:\n",
    "        harmonic_freq = 2 * fundamental_freq\n",
    "        harmonic_range = (harmonic_freq - 5, harmonic_freq + 5)\n",
    "        energy_of_interest += np.sum(pxx[harmonic_range[0]:harmonic_range[1]])\n",
    "\n",
    "    energy_of_remaining = np.sum(pxx) - energy_of_interest\n",
    "    ratio = energy_of_interest / (energy_of_remaining + 1e-17)\n",
    "    snr = 10 * np.log10(ratio)\n",
    "\n",
    "    return snr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = 10 #(*) file_num에 맞게 불러오면 됨 #file_num은 video.ipynb 파일에서 이미지 저장할때 폴더명(=path_num)\n",
    "file_path = 'images_2/%d'%file_num\n",
    "\n",
    "rgb_signal = run(file_path, file_num)\n",
    "\n",
    "# CHROM 검출\n",
    "raw_signal = np.array(rgb_signal).transpose()\n",
    "detrended = detrending(raw_signal, fs)\n",
    "detrended = detrended.transpose()\n",
    "X = 3 * detrended[0] - 2 * detrended[1]\n",
    "Y = 1.5 * detrended[0] + detrended[1] - 1.5 * detrended[2]\n",
    "Xf = temporal_bandpass_filter(X, fs, minBPM, maxBPM)\n",
    "Yf = temporal_bandpass_filter(Y, fs, minBPM, maxBPM)\n",
    "alpha = np.std(Xf) / np.std(Yf)\n",
    "chrom_signal = Xf - alpha * Yf\n",
    "\n",
    "# 주파수 스펙트럼\n",
    "f, chrom_spectrum = signal.periodogram(chrom_signal, fs=fs, window='hann')\n",
    "\n",
    "# 맥박수 추정\n",
    "pr = estimate_average_pulserate(chrom_signal, fs, minBPM, maxBPM)\n",
    "\n",
    "# 그래프 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(chrom_signal, 'b', linewidth=2)\n",
    "plt.xlim([0, len(chrom_signal)])\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.plot(f, chrom_spectrum, 'k', linewidth=2)\n",
    "plt.scatter(f[np.argmax(chrom_spectrum)], np.max(chrom_spectrum), c='r', marker='x')\n",
    "plt.xlim([0, fs//2])\n",
    "plt.text(f[np.argmax(chrom_spectrum)] + 1, np.max(chrom_spectrum), '%d bpm' % pr, fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rppg",
   "language": "python",
   "name": "rppg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}